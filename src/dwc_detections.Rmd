---
title: "Import detections data"
subtitle: "ETN - LifeWatch.be acoustic telemetry data of fish"
author:
- Lien Reysehove
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Install packages

```{r}
library(tidyverse)      # To do data science
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(etn)            # To interact with ETN
library(lubridate)      # To process date and time information
library(glue)
library(odbc)
```

# Read source data

Get username/password from environment (therefore requires this script to be run on <http://rstudio.lifewatch.be>) and connect to database:

```{r}
my_con <- connect_to_etn(Sys.getenv("username"), Sys.getenv("password"))
```

# Select transmitter and reciever information

Inspect `vliz.animals_view`:

```{r}
query <- glue_sql(
    "SELECT *
    FROM vliz.animals_view
    LIMIT 100000
    ",
    .con = my_con
  )
  
animals_subset <- dbGetQuery(my_con, query)
as_tibble(animals_subset)
```

Select all tag information from all animal projects of interest:

```{r}
detections_query <- glue_sql(
    "SELECT DISTINCT transmitter
    FROM vliz.detections_view AS detections
    WHERE 
      (animal_project_code = '2011_rivierprik' 
        OR animal_project_code = '2012_leopoldkanaal'
        OR animal_project_code = '2013_albertkanaal'
        OR animal_project_code = '2014_demer'
        OR animal_project_code = '2015_dijle'
        OR (animal_project_code = '2015_phd_verhelst' AND scientific_name = 'Anguilla anguilla')
        OR animal_project_code = 'homarus'
        OR animal_project_code = 'phd_reubens')
      AND NOT scientific_name = 'Sentinel'
      AND NOT scientific_name = 'Sync tag'" ,
    .con = my_con)

transmitters <- dbGetQuery(my_con, detections_query)
as_tibble(transmitters)
```

Create vector `transmitters`, to incorporate later in SQL selection criterium:

```{r}
transmitters <- transmitters %>% pull(transmitter)
```

Information in the vector `transmitters` should also be in `vliz.animals_view`. The following code selects for all transmitters that **do not occur** in the `vliz.animals_view` table. This should ideally return an empty tibble:

```{r}
detections_query <- glue_sql(
    "SELECT transmitter
    FROM vliz.detections_view AS detections
    WHERE 
      transmitter IN ({transmitters*})
      AND transmitter NOT IN
        (SELECT tag_full_id
        FROM vliz.animals_view
        WHERE tag_full_id = detections.transmitter)",
    transmitters = transmitters,
    .con = my_con
  )
tags_not_my_animals <- dbGetQuery(my_con, detections_query)
as_tibble(tags_not_my_animals)
```

Extract all receiver information involved in the detection of the specific transmitters:

```{r}
detections_query <- glue_sql(
    "SELECT DISTINCT receiver 
    FROM vliz.detections_view AS detections
    WHERE transmitter IN ({transmitters*})",
    transmitters = transmitters,
    .con = my_con
  )
receivers <- dbGetQuery(my_con, detections_query)
as_tibble(receivers)
```

Use information in receiver to select on receiver information in `vliz.deployments_view`

```{r}
receivers <- receivers %>% pull(receiver)
```

Extract all deployment information for the specific receivers:

```{r}
query <- glue_sql(
    "SELECT *
    FROM vliz.deployments_view
    WHERE receiver IN ({receiver*})
    ORDER BY receiver
    ",
    receiver = receivers,
    .con = my_con)

deployments <- dbGetQuery(my_con, query)
as_tibble(deployments)
```

Export `deployments` as .csv:

```{r}
write_csv(deployments, "../data/interim/deployments.csv", na = "")
```

## Explore deployment information

### receiver

```{r}
deployments %>% group_by(receiver) %>% count() %>% arrange(desc(n))
```

### receiver status

```{r}
deployments %>% group_by(receiver_status) %>% count() %>% arrange(desc(n))
```

### project name

```{r}
deployments %>% 
  group_by(projectname) %>% 
  count() %>% 
  arrange(projectname)
```

Check whether these projectnames are valid network project (should be zero):

```{r}
deployments %>% 
  group_by(projectname) %>% 
  count() %>% 
  arrange(projectname) %>% 
  anti_join(
    select(get_projects(my_con, project_type = "network"), name),
    by = c("projectname" = "name")
)
```

### drop dead date

```{r}
deployments %>% group_by(drop_dead_date) %>% count() %>% arrange(desc(n))
```

### deploy and recover date

Inspect both `deploy_date_time` and `recover_date_time`:

```{r}
deployments %>% 
  group_by(deploy_date_time, recover_date_time) %>% 
  count() %>% 
  arrange(desc(n))
```

Check for empty values in `deploy_date_time`, `recover_date_time` or both:

```{r}
deployments %>% 
  mutate(deploy_date_time = as.character(deploy_date_time)) %>% 
  mutate(recover_date_time = as.character(recover_date_time)) %>% 
  mutate(empty_dates = case_when(
    is.na(deploy_date_time) & !is.na(recover_date_time) ~ "no deploy date available",
    !is.na(deploy_date_time) & is.na(recover_date_time) ~ "no recover date available",
    is.na(deploy_date_time) & is.na(recover_date_time) ~ "no date information available",
    TRUE ~ "deploy and recover date available")) %>% 
  group_by(empty_dates) %>% 
  count()
```

All receivers have at least a deployment date available.
Retrieve record for which there is no recover date information available:

```{r}
deployments %>% 
  mutate(deploy_date_time = as.character(deploy_date_time)) %>% 
  mutate(recover_date_time = as.character(recover_date_time)) %>% 
  mutate(empty_dates = case_when(
    is.na(deploy_date_time) & !is.na(recover_date_time) ~ "no deploy date available",
    !is.na(deploy_date_time) & is.na(recover_date_time) ~ "no recover date available",
    is.na(deploy_date_time) & is.na(recover_date_time) ~ "no date information available",
    TRUE ~ "deploy and recover date available")) %>% 
  filter(empty_dates == "no recover date available") %>% 
  select(receiver, receiver_status, projectname, id_pk) %>% 
  arrange(receiver_status)
```

Retrieve receiver deployments for which `recover_date_time` falls before `deploy_date_time`:

```{r}
deployments %>% 
  mutate(deploy_date_time = as.character(deploy_date_time)) %>% 
  mutate(recover_date_time = as.character(recover_date_time)) %>% 
  mutate(empty_dates = case_when(
    is.na(deploy_date_time) & !is.na(recover_date_time) ~ "no deploy date available",
    !is.na(deploy_date_time) & is.na(recover_date_time) ~ "no recover date available",
    is.na(deploy_date_time) & is.na(recover_date_time) ~ "no date information available",
    TRUE ~ "deploy and recover date available"))%>% 
  filter(recover_date_time < deploy_date_time) %>% 
  arrange(receiver) %>% 
  select(receiver, recover_date_time, deploy_date_time, id_pk, projectname)
```

### bottom depth, riser length and instrument depth

```{r}
deployments %>% 
  group_by(bottom_depth, riser_length, instrument_depth) %>% 
  count() %>% 
  arrange(desc(n))
```

Unit of `bottom_depth`: metres
Unit of `riser_length`: metres
unit of `instrument_depth`: metres

Select those records with a unit in `bottom_depth` (see #58)

```{r}
deployments %>% 
  filter(str_detect(bottom_depth,"m")) %>% 
  select(receiver, id_pk, bottom_depth, projectcode) %>% 
  arrange(receiver)
```

### UTC synchronisation date time

```{r}
deployments %>% 
  group_by(sync_date_time) %>% 
  count() %>% 
  arrange(desc(n))
```

### comments

See [issue 59](https://github.com/inbo/etn-occurrences/issues/59)

```{r}
deployments %>% 
  group_by(comments) %>% 
  count() %>% 
  arrange(desc(n))
```

### id_pk

Should all be unique (output should be empty)

```{r}
deployments %>% get_dupes(id_pk)
```

### location name

Generate `deployment_locations` to export as intermediate file:

```{r}
deployment_locations <-
  deployments %>% 
    filter(!is.na(location_name) | location_name == "") %>%
    group_by(projectname, location_name, location_description) %>% 
    count() %>% 
    arrange(projectname)
head(deployment_locations, n = 300)
```

Export as .csv to be reviewed by experts:

```{r}
write_csv(deployment_locations, "../data/interim/deployment_locations.csv", na = "")
```

### deployment latitude and longitude

Inspect deployment latitude and longitude:

```{r}
deployments %>% 
  group_by(deploy_lat, deploy_long) %>% 
  count()
```

### recover latitude and longitude

Inspect recover latitude and longitude:

```{r}
deployments %>% 
  group_by(recover_lat, recover_long) %>% 
  count()
```

Some values for `recover_lat` and `recover_long` are rather odd. 
- Zero values for `recover_lat` and `recover_long`
- Extreme low (5) values for `recover_lat`
- Negative or extreme high values (20) for `recover_long`

1. Identify zero values for `recover_lat` and `recover_long`:

```{r}
deployments %>% 
  filter(recover_lat == 0 |
           recover_long == 0) %>% 
  select(projectname, id_pk, recover_date_time) %>% 
  arrange(projectname) 
```

2. Identify deviating values for `recover_lat`:

```{r}
deployments %>% 
  filter(recover_lat != 0 & recover_lat < 50) %>% 
  select(projectname, id_pk, recover_lat, recover_long) %>% 
  arrange(projectname) 
```

3. Identify deviating values for `recover_long`:

```{r}
deployments %>% 
  filter(recover_long != 0 & (recover_long < 0 | recover_long > 10)) %>% 
  select(projectname, id_pk, recover_lat, recover_long) %>% 
  arrange(projectname) 
```

### station name

```{r}
deployments %>% group_by(station_name) %>% count()
```


### intended latitude and longitude


```{r}
deployments %>% 
  group_by(intended_lat, intended_long) %>% 
  count()
```
